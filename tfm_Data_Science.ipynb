{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import GetOldTweets3 as got\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from googletrans import Translator\n",
    "import socket as sk\n",
    "from datetime import *\n",
    "import tweepy\n",
    "import re\n",
    "import string\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuración de parámetros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 5000\n",
    "pd.options.display.max_rows = 5000\n",
    "sk.setdefaulttimeout(600)\n",
    "\n",
    "#Variable de autentificación en Twitter\n",
    "OAUTH_TOKEN='1204477616398503936-7Z5WSIa0490S7HbIoPrDzosdA8aJKb'\n",
    "OAUTH_SECRET='OCHWxZGQlrnaoNx4corTWHNZPrtGtItteYnow7nMDhtON'\n",
    "CONSUMER_KEY='IRuah0diiQDx7ayuHaFmCOvTq'\n",
    "CONSUMER_SECRET='FkYZE9vZXWMgWvovRjcqQaixPleh6ADXdD3XU05ZsIkscSFzXd'\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY,CONSUMER_SECRET)\n",
    "auth.set_access_token(OAUTH_TOKEN,OAUTH_SECRET)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True, timeout=3600)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('display.width',None)\n",
    "pd.set_option('max_colwidth',-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecución de clases y métodos del proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Metodos_Propios.ipynb\n",
    "%run Gestion_Ficheros.ipynb\n",
    "%run GetOldTweets.ipynb\n",
    "%run NLP.ipynb\n",
    "%run Extract_Twitter_v2.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Método Principal - TFM Data Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comienzo del programa:  08/12/2020, 20:32:52\n",
      "Opción Un fichero:  CSVs/info_tweets_el_corte_ingles_202003.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    #Control horario programa\n",
    "    fecha_inicio = datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "    print('Comienzo del programa: ',fecha_inicio)\n",
    "    \n",
    "    # Definición de variables\n",
    "    fichero = 'CSVs/info_tweets_el_corte_ingles_202003.csv'\n",
    "    pattern = 'CSVs/info_tweets_el_corte_ingles*.csv'\n",
    "    fichero_user = 'CSVs/following_info_el_corte_ingles.csv'\n",
    "    fichero_tweets = 'CdM/Tweets_Info.csv'\n",
    "    fichero_fact = 'CdM/Tweets_Fact_Info.csv'\n",
    "    following_ids = []  \n",
    "    calendario = calendar()\n",
    "    df_tweets, df_tweets_final, df_following, df_fact_following = creacion_DataFrame()\n",
    "    #positivo, negativo, neutral, sentiment = creacion_Variables()\n",
    "    \n",
    "    #Flujo de la información\n",
    "    online = 0\n",
    "    all_tweets = 0\n",
    "    online_user = 0\n",
    "    \n",
    "    #Definición POO\n",
    "    file = File_Manage()\n",
    "    #file.initValues(fichero, pattern)\n",
    "    gotTweets = GoT(calendario)\n",
    "    nlp = NLP()\n",
    "    google = Translator()\n",
    "    \n",
    "    #Acceso a Twitter\n",
    "    api = acceso_Twitter() \n",
    "\n",
    "    \n",
    "    #Obtención por GetOldTweets\n",
    "    if online == 1:\n",
    "        print('Opción Online')\n",
    "        print(gotTweets.getCalendar())\n",
    "        df_tweets = gotTweets.get_Tweets(gotTweets.getCalendar())\n",
    "    #Lectura de ficheros para ir más rápido ubicados en CSVs\n",
    "    elif all_tweets == 1:\n",
    "        file.setPattern(pattern)\n",
    "        print('Opción Offline Tweets: ', file.getPattern())\n",
    "        df_tweets = file.read_all_Tweets(file.getPattern()) \n",
    "\n",
    "    else: \n",
    "        file.setFile(fichero)\n",
    "        print('Opción Un fichero: ', file.getFile())\n",
    "        df_tweets = file.read_Tweets(file.getFile())\n",
    "        \n",
    "    df_tweets['valor'] = -10\n",
    "    df_tweets['fecha'] = df_tweets['date'].astype(str).str[:10]\n",
    "    df_tweets['fecha'] = df_tweets['fecha'].str.replace('-','/')\n",
    "    df_tweets['objetividad'] = 0\n",
    "    df_tweets['subjetividad'] = 0\n",
    "\n",
    "    df_tweets['Tweet_punct'] = df_tweets['text'].str.lower().apply(lambda text: nlp.eliminar_signos(text))\n",
    "    df_tweets['Tweet_traduccion'] = df_tweets['Tweet_punct'].apply(lambda text: google.translate(text,dest='es').text)\n",
    "    df_tweets['Tweet_token'] = df_tweets['Tweet_traduccion'].apply(lambda text: nlp.tokenization(text))\n",
    "    df_tweets['Tweet_novacias'] = df_tweets['Tweet_token'].apply(lambda text: nlp.quitar_palabras_vacias(text))\n",
    "    df_tweets['Tweet_novacias'] = df_tweets['Tweet_novacias'].apply(lambda text: listToString(text))\n",
    "\n",
    "    \n",
    "    #Pasando el algoritmo de NLP para obtener el análisis de sentimiento\n",
    "    df_tweets_final = nlp.analisis(df_tweets)\n",
    "\n",
    "    nlp.nube_palabras(df_tweets_final)\n",
    "\n",
    "    \n",
    "    #Generación de CSVs para el CdM\n",
    "    file.setFile(fichero_tweets)\n",
    "    #file.writeCSV(df_tweets_final,file.getFile())\n",
    "    \n",
    "    #Para el caso de los usuarios followings, se crea un minimodelo de datos\n",
    "    if online_user == 1:\n",
    "        following_ids = get_following_ids(api)\n",
    "        following_limit=[following_ids[n:n+99] for n in range(0, len(following_ids), 100)]\n",
    "        df_following = pd.DataFrame(get_info_following(api,following_limit))\n",
    "        file.setFile(fichero_user)\n",
    "        file.writeCSV(df_following,file.getFile())\n",
    "    else:\n",
    "        file.setFile(fichero_user)\n",
    "        df_following = file.readCSV(df_following,file.getFile())\n",
    "     \n",
    "    df_tweets.columns = ['id_text','created_at_tweet','name_account','text','geo','valor','fecha','objetividad','subjetividad','Tweet_punct','Tweet_traduccion','Tweet_token','Tweet_novacias']\n",
    "\n",
    "    df_following.columns = ['id_account','name_account','screen_name_account','created_at_account','location_account','followers_account','friends_account','description_account']\n",
    "    df_fact_following = pd.merge(df_tweets, df_following,on=['name_account'],how='left')\n",
    "    df_fact_following = df_fact_following[df_fact_following['id_account'].notnull()]\n",
    "        \n",
    "    \n",
    "    file.setFile(fichero_fact)    \n",
    "    #file.writeCSV(df_fact_following,file.getFile())\n",
    "    \n",
    "    fecha_fin = datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "    print('Hora de Finalizacion: ',fecha_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
